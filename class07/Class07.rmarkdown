---
title: "class07"
author: "Adithi Kumar"
format: pdf
editor: visual
---


# Clustering

We will start today's lab with clustering methods, in particular so-called K-means. The main function for this in R is 'kmeans()' .

Let's try it on some made up data where we know what the answer should be.


```{r}
 
x <- rnorm(10000, mean = 3, ) 
hist(x) 

```


60 points


```{r}
tmp <- c(rnorm(30, mean = 3), rnorm(30, mean = -3) )
#makes two colums: x = tmp and y = reverse of tmp 
x <- cbind(x=tmp, y = rev(tmp)) 
head(x)
```


We can pass this to the bast 'plot()' function to be quick


```{r}
plot(x) 

```

```{r}
# for kmeans() centers = number of clusters & nstart is the number of iterations you want to run ( the more the better)
k <- kmeans(x, centers = 2, nstart =20) 
k
```


\>Q1: How many points are in each cluster?


```{r}
k$size

```


\>Q2: Cluster membership?


```{r}
#which points are assigned to which cluster
k$cluster

```


\>Q3: Cluster Centers?


```{r}
# what are the cluster centers
k$centers
```


\>Q4: Plot my clustering results


```{r}
# color by cluster by using cluster membership k$cluster
plot(x, col = k$cluster, pch =16)
```


\>Q5: Cluster the data again into 4 groups and plot the results.


```{r}
# cluster x into 4 groups 
k4 <- kmeans(x, centers =4, nstart= 20)  
# plot with color by cluster using k4$cluster
plot(x, col =k4$cluster, pch = 15)
```


L-means is very popular mostly because it is fast and relatively straightforward to tun and understand. It has a big limitation in that you need to tell it how many groups (k, or centers) you want.

# Hierarchical Clustering 

Th main function in base R is called 'hclust()' . You cane to pass it in a "distance matrix" not just your input data.

You can generate a distance matrix with the 'dist()' function.


```{r}
hc <- hclust(dist(x)) 
hc 

```

```{r}
plot (hc) 

```


To find the clusters (cluster membership vector) from a 'hclust()' results we can "cut" the tree at a certain height that we like.


```{r}
plot(hc)  
# draw line at desired height with abline
abline(h=8, col = "darkred") 
# actually assign membership using 'cutree()' by assigning desired height 
grps <- cutree(hc, h = 8)
```

```{r}
table(grps)
```


Q6: Plot our hclust results.


```{r}
plot(x, col=grps)
```


# PCA 

## UK food data 


```{r}
url <- "https://tinyurl.com/UK-foods" 
y <- read.csv(url) 
```


**Q1**. How many rows and columns are in your new data frame named `x`? What R functions could you use to answer this questions?


```{r}
dim(y)
```

```{r}
## Preview the first 6 rows 
head(y) 

```

```{r}
## Rename so X is not the first column 
rownames(y) <- y[,1] 
y <- y[,-1] 
head(y) 

```

```{r}
dim(y)
```


Q2: Which approach to solving the 'row-names problem' mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I definitely like the second approach ( x \<- read.csv (url, row.names =1)). With the first approach, if I re-ran the same command, I would lose an additional column which can be difficult to fix or even notice if I wasn't careful. Reading it properly from the beginning (like what the second approach does) will help avoid this problem altogether.


```{r}
barplot(as.matrix(y), beside=T, col=rainbow(nrow(y)))
```


Q3: Changing what optional argument in the above barplot() function results in the following plot?


```{r}
barplot(as.matrix(y), beside=F, col=rainbow(nrow(y)))
```


By making the argument 'beside= F', the columns of height will be portrayed as stacked columns.

**Q5**: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?


```{r}
pairs(y, col=rainbow(10), pch=16)

```


Each plot from the resulting figure shows scatter-plots of a country vs. another country. Each colored point is a specific food. The points on the straight diagonal indicate that the specific food is consumed very similarly in both country. If the point is off of the diagonal line, this indicates that the specific food is NOT consumed similarly in both countries. Each point is a specific food.

Q6: What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

The plots that show N. Ireland vs. any of the other countries all have more off-diagonal points than any of the other countries. This indicates that there are more foods that are eaten differently between N. Ireland and the other countries of the UK than any other countries.

## Principal Component Analysis (PCA)  

PCA can help us make sense of these types of data sets. Let's see how it works!

The main function in "base" R is 'prcomp()' In this case, we want to first take the transpose of out input 'x' so the columns are the food types and the countries are the rows.


```{r}
head (t(y))
```

```{r}
pca <- prcomp(t(y)) 
summary(pca)
```

```{r}
pca$x

```


**Q7**. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.


```{r}
# Plot PC1 vs PC2
plot( pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(y))
```


**Q8.** Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.


```{r}
plot( pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(y),  col = c("orange", "red", "blue", "darkgreen"))
      
      
      
      
      
      

```


We can use the square of pca\$sdec to calculate how much variation in the ordinal data each PCs

The "loadings" tell us how much the original variables (in our case the foods) contribute to the new variables (sx. the PCs)


```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```

```{r}
z <- summary(pca)
z$importance

```

```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

```{r}
head(pca$roation) 
par(mar = c(10, 3, 0.35, 0)) 
barplot (pca$rotation[,1], las =2)
```

